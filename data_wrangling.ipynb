{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features in the datasets :\n",
    "\n",
    "- user_veritied : if the user is verified or not (converted to 0-1. Already in the base dataset)\n",
    "- user_statuses_count : already in the base dataset\n",
    "- user_followers_count : already in the base dataset\n",
    "- user_friends_count : already in the base dataset\n",
    "- hour : hour of the tweet\n",
    "- day : day of the tweet \n",
    "- month : month of the tweet\n",
    "- weekday : if the tweet is a weekend or not\n",
    "- friends_followers_ratio = user_friends_count/user_followers_count\n",
    "- has_hashtags : if the tweet has hastags or not\n",
    "- has_mentions : if the tweet has mentions or not\n",
    "- has_urls : if the tweet has an url or not\n",
    "- number_of_urls : the number of urls of a tweet\n",
    "- number_of_mentions : the number of mentions of a tweet\n",
    "- number_of_hashtags : the number of hashtags of a tweet\n",
    "- urls_popularity : the popularity of the urls of a tweet. If the tweet has urlA and urlB, urls_popularity = max(number of occurences of urlA in the database, number of occurences of urlB in the database)\n",
    "- hashtags_popularity : popularity of the hashtags of a tweet. The definition is similar as above\n",
    "- mentions_popularity : same as above\n",
    "- polarity : the polarity of a tweet computed using the textBlob library. It is a scalar between -1 and 1 that represents the positivity-negativity of the text of the tweet.\n",
    "- subjectivity : the subjectivity of a tweet computed using textBlob library. It is a scalar between 0 and 1 that tells us how much the tweet is subjective\n",
    "\n",
    "New features coming soon : the number of followers and friends of the users mentioned in a tweet. Must use the twitter API to compute this :( . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load both datasets and merge them because to compute the popularity of a given hashtag, url, or mention, all the data is needed.\n",
    "\n",
    "We will then load and merge the training and test set, and split them at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"data/train.csv\")\n",
    "df2 = pd.read_csv(\"data/evaluation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1.append(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>urls</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1588696955143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>68460</td>\n",
       "      <td>1101</td>\n",
       "      <td>1226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Smh I give up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1588464948124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>309</td>\n",
       "      <td>51</td>\n",
       "      <td>202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Most of us are Human Beings, but I think you m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1588634673360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3241</td>\n",
       "      <td>1675</td>\n",
       "      <td>2325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Old dirty tricks Trump, at it again...like we ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1588433158672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>32327</td>\n",
       "      <td>667</td>\n",
       "      <td>304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Seriously..... I worked 86 hours my last check...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1588582751599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>581</td>\n",
       "      <td>42</td>\n",
       "      <td>127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>May ALMIGHTY ALLAH have mercy on us all. Only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1588434563287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>7214</td>\n",
       "      <td>503</td>\n",
       "      <td>1126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>They couldn‚Äôt care less.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1588692966869</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>372</td>\n",
       "      <td>738</td>\n",
       "      <td>472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>twitter.com/i/web/status/1‚Ä¶</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>Extremely valid points being made here üëáüèæ #Eth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1588316892450</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2085</td>\n",
       "      <td>3808</td>\n",
       "      <td>153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>twitter.com/i/web/status/1‚Ä¶</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COVID-19 dominated the discussion Tuesday at a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1588625905286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>17765</td>\n",
       "      <td>11666</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BC now has 112 patients on ventilators.  17 of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1588604315931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3086</td>\n",
       "      <td>66</td>\n",
       "      <td>241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a COVID-19 vaccine would be pretty lit ngl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      timestamp  retweet_count  user_verified  user_statuses_count  \\\n",
       "0   0  1588696955143            0.0          False                68460   \n",
       "1   1  1588464948124            0.0          False                  309   \n",
       "2   2  1588634673360            0.0          False                 3241   \n",
       "3   3  1588433158672            0.0          False                32327   \n",
       "4   4  1588582751599            0.0          False                  581   \n",
       "5   5  1588434563287            0.0          False                 7214   \n",
       "6   6  1588692966869            2.0          False                  372   \n",
       "7   7  1588316892450            1.0          False                 2085   \n",
       "8   8  1588625905286            0.0          False                17765   \n",
       "9   9  1588604315931            0.0          False                 3086   \n",
       "\n",
       "   user_followers_count  user_friends_count user_mentions  \\\n",
       "0                  1101                1226           NaN   \n",
       "1                    51                 202           NaN   \n",
       "2                  1675                2325           NaN   \n",
       "3                   667                 304           NaN   \n",
       "4                    42                 127           NaN   \n",
       "5                   503                1126           NaN   \n",
       "6                   738                 472           NaN   \n",
       "7                  3808                 153           NaN   \n",
       "8                 11666                  40           NaN   \n",
       "9                    66                 241           NaN   \n",
       "\n",
       "                          urls  hashtags  \\\n",
       "0                          NaN       NaN   \n",
       "1                          NaN       NaN   \n",
       "2                          NaN       NaN   \n",
       "3                          NaN       NaN   \n",
       "4                          NaN       NaN   \n",
       "5                          NaN       NaN   \n",
       "6  twitter.com/i/web/status/1‚Ä¶  Ethiopia   \n",
       "7  twitter.com/i/web/status/1‚Ä¶       NaN   \n",
       "8                          NaN       NaN   \n",
       "9                          NaN       NaN   \n",
       "\n",
       "                                                text  \n",
       "0                                      Smh I give up  \n",
       "1  Most of us are Human Beings, but I think you m...  \n",
       "2  Old dirty tricks Trump, at it again...like we ...  \n",
       "3  Seriously..... I worked 86 hours my last check...  \n",
       "4  May ALMIGHTY ALLAH have mercy on us all. Only ...  \n",
       "5                           They couldn‚Äôt care less.  \n",
       "6  Extremely valid points being made here üëáüèæ #Eth...  \n",
       "7  COVID-19 dominated the discussion Tuesday at a...  \n",
       "8  BC now has 112 patients on ventilators.  17 of...  \n",
       "9         a COVID-19 vaccine would be pretty lit ngl  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just convert False to 0 and True to 1.\n",
    "\n",
    "df[\"user_verified\"] = df[\"user_verified\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don't know why I am supposed to take the modulo, but it works...\n",
    "# If I don't do that, I get a wrong date in 1970\n",
    "\n",
    "df['date']  =(df['timestamp']).astype(np.int64) // 10**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit = 's' puts the date in unix format. Necessary to get the good format.\n",
    "\n",
    "df['date']= pd.to_datetime(df['date'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"hour\"] = df[\"date\"].dt.hour\n",
    "df[\"day\"] = df[\"date\"].dt.day\n",
    "df[\"month\"] = df[\"date\"].dt.month\n",
    "\n",
    "# 0 for Monday\n",
    "df[\"weekday\"] = df[\"date\"].dt.weekday\n",
    "\n",
    "# If the day is a weekend or not\n",
    "df[\"weekend\"] = np.where(np.logical_or(df[\"weekday\"] == 5, df[\"weekday\"] == 6), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"friends_followers_ratio\"] = df[\"user_friends_count\"]/df[\"user_followers_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"has_hashtags\"] = np.where(pd.notnull(df[\"hashtags\"]), 1, 0)\n",
    "df[\"has_mentions\"] = np.where(pd.notnull(df[\"user_mentions\"]), 1, 0)\n",
    "df[\"has_urls\"] = np.where(pd.notnull(df[\"urls\"]), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stupid to use this fonction\n",
    "\n",
    "def counter(word):\n",
    "    if pd.isna(word):\n",
    "        return 0\n",
    "    number = 1\n",
    "    for s in word:\n",
    "        if s == ',':\n",
    "            number += 1\n",
    "    return number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"number_of_urls\"] = df[\"urls\"].apply(counter)\n",
    "df[\"number_of_mentions\"] = df[\"user_mentions\"].apply(counter)\n",
    "df[\"number_of_hashtags\"] = df[\"hashtags\"].apply(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will compute hashtags, urls, and mentions popularity. We computed it only on the given dataset. However it may be smarter to us it on ALL the data (both training and test).\n",
    "\n",
    "We :\n",
    "\n",
    "- Turn the urls, hashtags, and mentions into lists.\n",
    "- We create dictionnaries that will help us stock the number of occurences of urls, hashtags, and tweets.\n",
    "- We finally compute the popularity (popularity = number of occurences in the dataset) of the hashtags, urls, and mentions of a tweet, and the we take the maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An auxiliary function that, given a text, separates it\n",
    "# with commas (ie useful to get a list of hashtags, urls, mentions)\n",
    "\n",
    "def word_cut(word):\n",
    "    if pd.isna(word):\n",
    "        return []\n",
    "    word_array = np.array([])\n",
    "    l = 0\n",
    "    for i,s in enumerate(word):\n",
    "        if s == ',':\n",
    "            word_array = np.append(word_array, word[l:i])\n",
    "            l = i+1\n",
    "    word_array = np.append(word_array, word[l::])\n",
    "    return word_array\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a new column with the parsed elements. We will delete it in the end.\n",
    "\n",
    "df[\"urls_list\"] = df[\"urls\"].apply(word_cut)\n",
    "df[\"hashtags_list\"] = df[\"hashtags\"].apply(word_cut)\n",
    "df[\"mentions_list\"] = df[\"user_mentions\"].apply(word_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnaries that will contain the number of occurences of elements\n",
    "\n",
    "urls_pop = dict()\n",
    "hashtags_pop = dict()\n",
    "mentions_pop = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updates the counting of the occurences of a given element in one of the dictionaries defined above\n",
    "\n",
    "def stock(x, name):\n",
    "    if name == \"urls\":\n",
    "        if x in urls_pop.keys():\n",
    "            urls_pop[x] += 1\n",
    "        else :\n",
    "            urls_pop[x] = 0\n",
    "    if name == \"hashtags\":\n",
    "        if x in hashtags_pop.keys():\n",
    "            hashtags_pop[x] += 1\n",
    "        else :\n",
    "            hashtags_pop[x] = 0\n",
    "    if name == \"mentions\":\n",
    "        if x in mentions_pop.keys():\n",
    "            mentions_pop[x] += 1\n",
    "        else :\n",
    "            mentions_pop[x] = 0\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An auxiliary function that uses the function above on a array.\n",
    "\n",
    "def fill_dico(x, name):\n",
    "    for i in x:\n",
    "        stock (i, name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         None\n",
       "1         None\n",
       "2         None\n",
       "3         None\n",
       "4         None\n",
       "          ... \n",
       "665772    None\n",
       "665773    None\n",
       "665774    None\n",
       "665775    None\n",
       "665776    None\n",
       "Name: mentions_list, Length: 665777, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We apply the function above on the lists of urls, hashtags, and mentions\n",
    "\n",
    "df[\"urls_list\"].apply(fill_dico, args = (\"urls\",))\n",
    "df[\"hashtags_list\"].apply(fill_dico, args = (\"hashtags\",))\n",
    "df[\"mentions_list\"].apply(fill_dico, args = (\"mentions\",))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, a fonction that for a given array of urls, hashtags, or mentions, computes\n",
    "# the maximum popularity of the elements of the array.\n",
    "\n",
    "def compute_pop(x, name):\n",
    "    pop = 0\n",
    "    if name == \"urls\":\n",
    "        for i in x:\n",
    "            pop = max(pop, urls_pop[i])\n",
    "            \n",
    "    if name == \"hashtags\":\n",
    "        for i in x:\n",
    "            pop = max(pop, hashtags_pop[i])\n",
    "            \n",
    "    if name == \"mentions\":\n",
    "        for i in x:\n",
    "            pop = max(pop, mentions_pop[i])\n",
    "    \n",
    "    return pop\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We finally compute the popularity of the tweets\n",
    "\n",
    "df[\"urls_popularity\"] = df[\"urls_list\"].apply(compute_pop, args = (\"urls\",))\n",
    "df[\"hashtags_popularity\"] = df[\"hashtags_list\"].apply(compute_pop, args = (\"hashtags\",))\n",
    "df[\"mentions_popularity\"] = df[\"mentions_list\"].apply(compute_pop, args = (\"mentions\",))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We drop the parsed urls, hashtags, and mentions\n",
    "\n",
    "df = df.drop(columns=[\"urls_list\", \"hashtags_list\", \"mentions_list\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function that uses textBlob to return (polarity, subjectivity) of a tweet.\n",
    "\n",
    "# Polarity >= 0 -> positive \n",
    "# Polarity >= 0 -> negative\n",
    "\n",
    "# Subjectivity measures the subjectivity\n",
    "def sentiment(text):\n",
    "    try:\n",
    "        return TextBlob(text).sentiment\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This might take a little time, but on a good computer it shouldn't take more than a few minutes\n",
    "\n",
    "df['polarity']     = df[\"text\"].apply(sentiment).apply(lambda x: x[0])\n",
    "df['subjectivity'] = df[\"text\"].apply(sentiment).apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.iloc[:665777,:]\n",
    "df2 = df.iloc[665777:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('data/partially_treated_train_data.csv', index = False)\n",
    "df2.to_csv('data/partially_treated_evaluation_data.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
