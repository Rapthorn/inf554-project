{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "from verstack.stratified_continuous_split import scsplit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need some time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity:  0.7514804\n",
      "Similarity:  0.06448189\n",
      "Similarity:  0.4482424\n"
     ]
    }
   ],
   "source": [
    "# test the language model\n",
    "\n",
    "phrases_embed = embed([\"The capital of France is Paris\", \"Paris is the biggest french city\"])\n",
    "print( \"Similarity: \", ( sum( phrases_embed[0] * phrases_embed[1] ).numpy() ) )\n",
    "\n",
    "phrases_embed = embed([\"The capital of France is Paris\", \"I would like some coffee\"])\n",
    "print( \"Similarity: \", sum( phrases_embed[0] * phrases_embed[1] ).numpy() )\n",
    "\n",
    "phrases_embed = embed([\"Some black tea with sugar, please\", \"I would like some coffee\"])\n",
    "print( \"Similarity: \", sum( phrases_embed[0] * phrases_embed[1] ).numpy() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210088                                           CALLED IT.\n",
      "353448    first, manufacture the evidence, sell it to al...\n",
      "110884    The best part of Trump‚Äôs Fox News town hall is...\n",
      "118100    Because it‚Äôs Africa...the world won‚Äôt take it ...\n",
      "213235    Troubling development out of Trousdale Correct...\n",
      "41954                                             Ya think.\n",
      "493307               This is so sad! He was the best of us.\n",
      "99564                                     2020 is fucked up\n",
      "248579     The rich are getting richer off the Corona Virus\n",
      "377307    How long until we admit coronavirus has direct...\n",
      "Name: text, dtype: object\n",
      "tf.Tensor(\n",
      "[[ 0.00281394  0.00676178  0.00043603 ... -0.01381203  0.01512007\n",
      "   0.00630505]\n",
      " [-0.01473356 -0.06944113  0.0046551  ... -0.00106915 -0.0253217\n",
      "  -0.01710856]\n",
      " [ 0.00447236 -0.00602912 -0.03080316 ... -0.00867151 -0.0626659\n",
      "   0.05444583]\n",
      " ...\n",
      " [-0.06370888 -0.06671701  0.00352778 ... -0.02371787  0.00076623\n",
      "  -0.02998426]\n",
      " [ 0.01011501 -0.04472246  0.01779229 ... -0.05217279 -0.03629337\n",
      "  -0.06184245]\n",
      " [ 0.00451679 -0.04017515 -0.06433453 ...  0.00942981  0.00769876\n",
      "   0.00191677]], shape=(10, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"./data/train.csv\")\n",
    "X_train, X_test, y_train, y_test = scsplit(train_data, train_data['retweet_count'], stratify=train_data['retweet_count'], train_size=0.75, test_size=0.25)\n",
    "X_train = X_train.drop(['retweet_count'], axis=1)\n",
    "X_test = X_test.drop(['retweet_count'], axis=1)\n",
    "\n",
    "X_train = X_train[\"text\"]\n",
    "X_test = X_test[\"text\"]\n",
    "print(X_train[:10])\n",
    "print(embed(X_train[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed the Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CALLED IT.',\n",
       "       'first, manufacture the evidence, sell it to all the frauds, compare notes with each other, and call it verified.',\n",
       "       'The best part of Trump‚Äôs Fox News town hall is the long commercial breaks.',\n",
       "       ...,\n",
       "       'On the front line - Taoiseach @LeoVaradkar at Morgans Place site in Blachardstown where he he help with #Covid19 testing of residents. This sends out a really positive message üëèüèªüëèüèªüëèüèª https://t.co/neqoZ817dZ',\n",
       "       '‡Æ™‡ØÜ‡Æ∞‡ØÅ‡Æ®‡Æï‡Æ∞ ‡Æö‡ØÜ‡Æ©‡Øç‡Æ©‡Øà ‡ÆÆ‡Ææ‡Æ®‡Æï‡Æ∞‡Ææ‡Æü‡Øç‡Æö‡Æø‡ÆØ‡Æø‡Æ≤‡Øç, ‡Æï‡Øä‡Æ∞‡Øã‡Æ©‡Ææ ‡Æ™‡Ææ‡Æ§‡Æø‡Æ™‡Øç‡Æ™‡Æø‡Æ≤‡Øç ‡Æá‡Æ∞‡ØÅ‡Æ®‡Øç‡Æ§‡ØÅ ‡Æï‡ØÅ‡Æ£‡ÆÆ‡Æü‡Øà‡Æ®‡Øç‡Æ§‡Æµ‡Æ∞‡Øç‡Æï‡Æ≥‡Øç, ‡Æ§‡Æ±‡Øç‡Æ™‡Øã‡Æ§‡ØÅ ‡Æö‡Æø‡Æï‡Æø‡Æö‡Øç‡Æö‡Øà ‡Æ™‡ØÜ‡Æ∞‡ØÅ‡Æ™‡Æµ‡Æ∞‡Øç‡Æï‡Æ≥‡Æø‡Æ©‡Øç ‡ÆÆ‡Æ£‡Øç‡Æü‡Æ≤‡Æµ‡Ææ‡Æ∞‡Æø ‡Æµ‡Æø‡Æµ‡Æ∞‡ÆÆ‡Øç #polimer #polimernews #coronavirus #Covid19 #GreaterChennaiCorporation https://t.co/ZWeX88fALk',\n",
       "       '#Ofcom are a joke not fit for purpose what did they do about #FakeNews at the #BBC to justify bombing #Syria and #Iraq? If #5G turns out to be unsafe and people are harmed this woman and Ofcom will be finished. #NHS #BarCouncil #MisconductinPublicOffice #coronavirus #Rothschild https://t.co/c2mMOWFSxN'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "499332"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_embed = np.zeros( (X_train.shape[0], 512) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "116000\n",
      "117000\n",
      "118000\n",
      "119000\n",
      "120000\n",
      "121000\n",
      "122000\n",
      "123000\n",
      "124000\n",
      "125000\n",
      "126000\n",
      "127000\n",
      "128000\n",
      "129000\n",
      "130000\n",
      "131000\n",
      "132000\n",
      "133000\n",
      "134000\n",
      "135000\n",
      "136000\n",
      "137000\n",
      "138000\n",
      "139000\n",
      "140000\n",
      "141000\n",
      "142000\n",
      "143000\n",
      "144000\n",
      "145000\n",
      "146000\n",
      "147000\n",
      "148000\n",
      "149000\n",
      "150000\n",
      "151000\n",
      "152000\n",
      "153000\n",
      "154000\n",
      "155000\n",
      "156000\n",
      "157000\n",
      "158000\n",
      "159000\n",
      "160000\n",
      "161000\n",
      "162000\n",
      "163000\n",
      "164000\n",
      "165000\n",
      "166000\n",
      "167000\n",
      "168000\n",
      "169000\n",
      "170000\n",
      "171000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-8a098386dedc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m1000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mX_train_embed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36m_call_attribute\u001b[1;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_call_attribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    604\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 606\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    607\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for index, x in enumerate(X_train):\n",
    "    if index % 1000 == 0:\n",
    "        print(index)\n",
    "    X_train_embed[index, :] = embed([x]).numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_embed = X_train_embed[:10000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 512)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0, 89, ...,  0,  0,  1], dtype=int64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build up the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1, 'relu'))\n",
    "    model.compile(loss=\"mse\", optimizer='adam', metrics=[\"mse\"])\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00281393,  0.0067618 ,  0.00043604, ..., -0.01381206,\n",
       "         0.01512006,  0.00630507],\n",
       "       [-0.01473355, -0.06944113,  0.00465509, ..., -0.00106913,\n",
       "        -0.02532168, -0.01710855],\n",
       "       [ 0.00447234, -0.00602915, -0.03080317, ..., -0.00867152,\n",
       "        -0.06266589,  0.05444582],\n",
       "       ...,\n",
       "       [-0.04201492,  0.03147441,  0.03473513, ...,  0.06916818,\n",
       "         0.00319515, -0.1078413 ],\n",
       "       [-0.07394182, -0.00274012,  0.08254025, ..., -0.05593901,\n",
       "        -0.02026385, -0.02183842],\n",
       "       [ 0.01431507,  0.06577744, -0.00417293, ..., -0.02583069,\n",
       "        -0.07258449, -0.04139128]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array( X_train_embed )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/50\n",
      "8000/8000 [==============================] - 1s 158us/sample - loss: 7768035.9216 - mse: 7768036.0000 - val_loss: 1476889.8475 - val_mse: 1476889.8750\n",
      "Epoch 2/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 7709581.3765 - mse: 7709582.0000 - val_loss: 1468968.9283 - val_mse: 1468968.8750\n",
      "Epoch 3/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 7596514.0077 - mse: 7596514.0000 - val_loss: 1557479.4981 - val_mse: 1557479.3750\n",
      "Epoch 4/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 6716366.0275 - mse: 6716366.0000 - val_loss: 2400466.5145 - val_mse: 2400466.7500\n",
      "Epoch 5/50\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 2421334.1502 - mse: 2421334.0000 - val_loss: 2017700.7858 - val_mse: 2017700.7500\n",
      "Epoch 6/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 1953517.2414 - mse: 1953517.2500 - val_loss: 2235880.2734 - val_mse: 2235880.5000\n",
      "Epoch 7/50\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 1854103.0834 - mse: 1854103.2500 - val_loss: 1711913.4921 - val_mse: 1711913.6250\n",
      "Epoch 8/50\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 1712176.9827 - mse: 1712177.0000 - val_loss: 2035710.6114 - val_mse: 2035710.5000\n",
      "Epoch 9/50\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 1488086.8373 - mse: 1488086.7500 - val_loss: 3211475.3195 - val_mse: 3211475.5000\n",
      "Epoch 10/50\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 2924070.5479 - mse: 2924070.7500 - val_loss: 1471479.7252 - val_mse: 1471479.6250\n",
      "Epoch 11/50\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 5118575.4481 - mse: 5118574.5000 - val_loss: 2258913.5109 - val_mse: 2258913.2500\n",
      "Epoch 12/50\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 1958184.8408 - mse: 1958185.0000 - val_loss: 1603514.4521 - val_mse: 1603514.5000\n",
      "Epoch 13/50\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 1806484.8666 - mse: 1806484.5000 - val_loss: 1796163.4365 - val_mse: 1796163.5000\n",
      "Epoch 14/50\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 1440264.1759 - mse: 1440264.1250 - val_loss: 2798490.8218 - val_mse: 2798491.0000\n",
      "Epoch 15/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 2854355.6476 - mse: 2854355.7500 - val_loss: 1505982.2870 - val_mse: 1505982.3750\n",
      "Epoch 16/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 2672259.7357 - mse: 2672259.5000 - val_loss: 1815074.1245 - val_mse: 1815074.1250\n",
      "Epoch 17/50\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 1241989.4447 - mse: 1241989.3750 - val_loss: 2384944.9087 - val_mse: 2384945.0000\n",
      "Epoch 18/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 1749967.6430 - mse: 1749967.6250 - val_loss: 1850216.9680 - val_mse: 1850217.0000\n",
      "Epoch 19/50\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 791618.7639 - mse: 791618.6875 - val_loss: 1620572.8653 - val_mse: 1620572.7500\n",
      "Epoch 20/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 505353.8079 - mse: 505353.7500 - val_loss: 2005988.0592 - val_mse: 2005988.1250\n",
      "Epoch 21/50\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 303901.9924 - mse: 303902.0312 - val_loss: 1838039.2475 - val_mse: 1838039.2500\n",
      "Epoch 22/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 328443.7423 - mse: 328443.7500 - val_loss: 1925808.1323 - val_mse: 1925808.1250\n",
      "Epoch 23/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 295647.9783 - mse: 295648.0312 - val_loss: 2201910.4925 - val_mse: 2201910.2500\n",
      "Epoch 24/50\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 259897.1797 - mse: 259897.2031 - val_loss: 1758954.0055 - val_mse: 1758953.8750\n",
      "Epoch 25/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 250140.4977 - mse: 250140.5312 - val_loss: 2144938.3788 - val_mse: 2144938.5000\n",
      "Epoch 26/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 385649.4355 - mse: 385649.4062 - val_loss: 1960326.8566 - val_mse: 1960326.8750\n",
      "Epoch 27/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 363236.5228 - mse: 363236.5000 - val_loss: 2000695.3723 - val_mse: 2000695.3750\n",
      "Epoch 28/50\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 262698.3645 - mse: 262698.3438 - val_loss: 1767632.4217 - val_mse: 1767632.2500\n",
      "Epoch 29/50\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 237656.0381 - mse: 237656.0469 - val_loss: 1827978.2895 - val_mse: 1827978.2500\n",
      "Epoch 30/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 307243.2778 - mse: 307243.2500 - val_loss: 1969115.6198 - val_mse: 1969115.5000\n",
      "Epoch 31/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 301705.3558 - mse: 301705.3438 - val_loss: 1971690.6466 - val_mse: 1971690.5000\n",
      "Epoch 32/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 337758.1534 - mse: 337758.1875 - val_loss: 2394791.4265 - val_mse: 2394791.5000\n",
      "Epoch 33/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 937112.8052 - mse: 937112.8125 - val_loss: 2014854.6154 - val_mse: 2014854.5000\n",
      "Epoch 34/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 872373.3094 - mse: 872373.2500 - val_loss: 2217460.6110 - val_mse: 2217460.7500\n",
      "Epoch 35/50\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 1501276.4803 - mse: 1501276.2500 - val_loss: 1480820.8136 - val_mse: 1480820.8750\n",
      "Epoch 36/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 1333997.1167 - mse: 1333997.1250 - val_loss: 2209571.7540 - val_mse: 2209571.5000\n",
      "Epoch 37/50\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 763033.2759 - mse: 763033.3750 - val_loss: 1527510.7375 - val_mse: 1527510.7500\n",
      "Epoch 38/50\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 1256909.6842 - mse: 1256909.6250 - val_loss: 1633820.6854 - val_mse: 1633820.6250\n",
      "Epoch 39/50\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 758705.0097 - mse: 758705.0625 - val_loss: 1681855.0060 - val_mse: 1681855.0000\n",
      "Epoch 40/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 618396.3358 - mse: 618396.3750 - val_loss: 1802284.8926 - val_mse: 1802284.7500\n",
      "Epoch 41/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 241265.5223 - mse: 241265.5312 - val_loss: 1824819.3799 - val_mse: 1824819.3750\n",
      "Epoch 42/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 263846.4959 - mse: 263846.5000 - val_loss: 2146915.4174 - val_mse: 2146915.5000\n",
      "Epoch 43/50\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 284016.7421 - mse: 284016.7500 - val_loss: 2127242.8905 - val_mse: 2127243.0000\n",
      "Epoch 44/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 311063.9030 - mse: 311063.9375 - val_loss: 2008882.5547 - val_mse: 2008882.7500\n",
      "Epoch 45/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 514613.0069 - mse: 514613.0625 - val_loss: 1614506.5905 - val_mse: 1614506.6250\n",
      "Epoch 46/50\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 899725.7378 - mse: 899725.6875 - val_loss: 1978336.8477 - val_mse: 1978336.7500\n",
      "Epoch 47/50\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 539271.9107 - mse: 539272.0000 - val_loss: 1837938.6295 - val_mse: 1837938.3750\n",
      "Epoch 48/50\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 256560.0046 - mse: 256560.0156 - val_loss: 2079745.3906 - val_mse: 2079745.3750\n",
      "Epoch 49/50\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 169854.0426 - mse: 169854.0469 - val_loss: 1890362.2233 - val_mse: 1890362.0000\n",
      "Epoch 50/50\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 316351.5085 - mse: 316351.5000 - val_loss: 1668635.0632 - val_mse: 1668635.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19dc5767518>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.fit(X_train_embed, y_train, epochs=epochs, batch_size = batch_size, validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_74 (Dense)             multiple                  131328    \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             multiple                  257       \n",
      "=================================================================\n",
      "Total params: 526,337\n",
      "Trainable params: 526,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 16 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 16 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[15.925902]], dtype=float32)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([[X_train_embed[2]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
